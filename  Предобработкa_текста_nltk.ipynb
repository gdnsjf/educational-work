{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjJQ1UzHP12OaFjtkg5ssF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gdnsjf/educational-work/blob/main/%20%D0%9F%D1%80%D0%B5%D0%B4%D0%BE%D0%B1%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%BAa_%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%B0_nltk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Рассчитайте метрики TF-IDF для любых 3 песен на одном языке, которые вы сами выберите.\n",
        "Не забудьте, что нужно привести слова к начальной форме, убрать\n",
        "cтоп-слова. Удачи!"
      ],
      "metadata": {
        "id": "YG6BNWDlTs8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pymorphy2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "skJb_icGVdIB",
        "outputId": "c3dc443c-2c51-4e98-d94b-71c8c68e2fd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dawg-python>=0.7.1 (from pymorphy2)\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4 (from pymorphy2)\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docopt>=0.6 (from pymorphy2)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=b387262f2536d610a972f2ae7142c50aec12258fdbc0842eba718bdff980bdb7\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built docopt\n",
            "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YEgNEDSP1Zq",
        "outputId": "f0f5c4f5-580d-4385-c0f8-3777e30a266d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TF-IDF матрица:\n",
            "    беда  белоснежный  бессмысленный      бог  бояться  бросить   быстро     быть     вдох     весь  взгляд  вздёрнуть     вода  водосточный  вознестись  вообще    время      всё   вымыть   высота   глухой  говорить  горевать  гормональный  горький  готовый   далеко   делить  делиться     день  догорать  долгий  домофон     дура  дёрнуть     есть     ещё  жалость  забрать  заварить  завернуть   завыть  закричать  залиться  замереть  замолчать   заново  заплатить  заскулить    звук    земля   знать   значит  изнутри  исчезнуть   каждый    ключ  коктейль  колотить  комочек     край  крикнуть    крыло  кудато    кукла     лист    лишь  лопнуть   любить  маленький    место  множить      мой   мольба     мочь  навсегда  начисто     небо  непривычка    нитка     нога     ночь   ночью  обычно    один      оно  оригами  остановиться  остаться  отпустить  отравить   отсюда  первый  перемешаться   песня  пиксель     план  подряд  полюбить  пополам  посидеть  последний  потерять   почему  привязать  призрак   прийти  проверить  пролететь  просить   птичка  разлука  разорваться  расколоться  расписать  раствориться    ребро  румянец      сам  сделать   сейчас  сжаться  сильный  скомкать  слипнуться   слово  смяться  сорвать  спешить   спичка    сразу    стать  стереться      сто  стрельна  сыграть   танец     твой     тень  терафить   тихий   точно  треснуть      три    труба      ты  увеличить  угодный  узнать  уменьшиться  умирать  упустить    ухаб     фото     хлам  хлопушка  хлынуть   хотеть    хотя  целоваться    целый   часик  честной    число   чистый  щеколда    экран\n",
            "0.000000     0.112533       0.000000 0.225067  0.00000 0.000000 0.112533 0.112533 0.225067 0.000000 0.00000   0.112533 0.000000     0.000000    0.112533 0.00000 0.085584 0.000000 0.000000 0.000000 0.112533   0.00000  0.112533      0.000000 0.000000  0.00000 0.112533 0.000000   0.00000 0.066464  0.225067 0.00000 0.000000 0.000000 0.000000 0.000000 0.00000 0.000000 0.112533  0.000000   0.000000 0.000000   0.000000   0.00000  0.225067    0.00000 0.000000   0.000000   0.000000 0.00000 0.112533 0.00000 0.000000 0.000000   0.000000 0.000000 0.00000  0.000000  0.000000 0.000000 0.000000  0.112533 0.112533 0.00000 0.000000 0.000000 0.00000 0.000000 0.000000   0.000000 0.000000 0.000000 0.112533 0.112533 0.000000  0.000000 0.000000 0.112533    0.112533 0.000000 0.000000 0.000000 0.00000 0.00000 0.00000 0.112533 0.000000      0.000000  0.112533   0.000000  0.000000 0.112533 0.00000      0.000000 0.00000 0.000000 0.000000 0.00000  0.000000 0.000000   0.00000   0.225067   0.00000 0.000000   0.000000 0.112533 0.000000   0.000000   0.112533  0.00000 0.427922  0.00000     0.000000     0.112533   0.000000       0.00000 0.000000  0.00000 0.000000 0.450133 0.000000 0.000000 0.000000  0.000000    0.000000 0.00000 0.000000 0.000000 0.000000 0.225067 0.000000 0.000000   0.000000 0.000000  0.000000 0.000000 0.00000 0.000000 0.085584  0.000000 0.00000 0.00000  0.000000 0.000000 0.000000 0.00000   0.000000  0.00000 0.00000     0.112533  0.00000   0.00000 0.00000 0.000000 0.000000  0.000000 0.000000 0.000000 0.00000     0.00000 0.000000 0.00000 0.000000 0.000000 0.000000 0.000000 0.000000\n",
            "0.031711     0.000000       0.031711 0.000000  0.00000 0.031711 0.000000 0.000000 0.000000 0.000000 0.00000   0.000000 0.000000     0.000000    0.000000 0.00000 0.337640 0.265288 0.000000 0.031711 0.000000   0.00000  0.000000      0.031711 0.000000  0.00000 0.000000 0.031711   0.00000 0.018729  0.000000 0.00000 0.000000 0.031711 0.031711 0.031711 0.00000 0.031711 0.000000  0.000000   0.031711 0.031711   0.031711   0.00000  0.000000    0.00000 0.000000   0.031711   0.000000 0.00000 0.000000 0.00000 0.000000 0.031711   0.031711 0.031711 0.00000  0.031711  0.031711 0.031711 0.031711  0.000000 0.000000 0.00000 0.031711 0.031711 0.00000 0.443956 0.063422   0.031711 0.031711 0.031711 0.000000 0.000000 0.031711  0.031711 0.000000 0.000000    0.000000 0.031711 0.031711 0.031711 0.00000 0.00000 0.00000 0.000000 0.031711      0.443956  0.000000   0.031711  0.031711 0.000000 0.00000      0.221978 0.00000 0.031711 0.221978 0.00000  0.000000 0.063422   0.00000   0.000000   0.00000 0.031711   0.031711 0.000000 0.063422   0.031711   0.000000  0.00000 0.024117  0.00000     0.031711     0.000000   0.031711       0.00000 0.031711  0.00000 0.000000 0.000000 0.031711 0.031711 0.031711  0.031711    0.031711 0.00000 0.031711 0.000000 0.031711 0.000000 0.221978 0.221978   0.031711 0.063422  0.031711 0.031711 0.00000 0.024117 0.000000  0.000000 0.00000 0.00000  0.031711 0.031711 0.000000 0.00000   0.031711  0.00000 0.00000     0.000000  0.00000   0.00000 0.00000 0.031711 0.031711  0.031711 0.000000 0.024117 0.00000     0.00000 0.000000 0.00000 0.221978 0.221978 0.221978 0.000000 0.031711\n",
            "0.000000     0.000000       0.000000 0.000000  0.10616 0.000000 0.000000 0.000000 0.000000 0.212321 0.05308   0.000000 0.212321     0.212321    0.000000 0.05308 0.000000 0.080738 0.212321 0.000000 0.000000   0.05308  0.000000      0.000000 0.212321  0.05308 0.000000 0.000000   0.05308 0.094050  0.000000 0.05308 0.212321 0.000000 0.000000 0.000000 0.05308 0.000000 0.000000  0.212321   0.000000 0.000000   0.000000   0.05308  0.000000    0.10616 0.212321   0.000000   0.212321 0.05308 0.000000 0.05308 0.212321 0.000000   0.000000 0.000000 0.05308  0.000000  0.000000 0.000000 0.000000  0.000000 0.000000 0.05308 0.000000 0.000000 0.05308 0.000000 0.000000   0.000000 0.000000 0.000000 0.000000 0.000000 0.000000  0.000000 0.212321 0.000000    0.000000 0.000000 0.000000 0.000000 0.05308 0.05308 0.05308 0.000000 0.000000      0.000000  0.000000   0.000000  0.000000 0.000000 0.05308      0.000000 0.05308 0.000000 0.000000 0.05308  0.212321 0.000000   0.05308   0.000000   0.05308 0.000000   0.000000 0.000000 0.000000   0.000000   0.000000  0.05308 0.000000  0.05308     0.000000     0.000000   0.000000       0.05308 0.000000  0.05308 0.212321 0.000000 0.000000 0.000000 0.000000  0.000000    0.000000 0.05308 0.000000 0.212321 0.000000 0.000000 0.000000 0.000000   0.000000 0.000000  0.000000 0.000000 0.05308 0.040369 0.040369  0.212321 0.05308 0.05308  0.000000 0.000000 0.212321 0.10616   0.000000  0.05308 0.05308     0.000000  0.05308   0.05308 0.05308 0.000000 0.000000  0.000000 0.212321 0.080738 0.05308     0.05308 0.159241 0.05308 0.000000 0.000000 0.000000 0.212321 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pymorphy2\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "\n",
        "# Загрузка стоп-слов\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('russian'))\n",
        "\n",
        "# Инициализация морфологического анализатора\n",
        "morph = pymorphy2.MorphAnalyzer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Удаление пунктуации и приведение к нижнему регистру\n",
        "    text = re.sub(r'[^\\w\\s]', '', text).lower()\n",
        "    # Лемматизация и удаление стоп-слов\n",
        "    tokens = text.split()\n",
        "    lemmatized_tokens = [morph.parse(token)[0].normal_form for token in tokens if token not in stop_words]\n",
        "    return ' '.join(lemmatized_tokens)\n",
        "\n",
        "# Функция для чтения текстов из файлов\n",
        "def read_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        return file.read()\n",
        "\n",
        "# Чтение текстов песен из файлов\n",
        "song_1 = read_file('song1.txt')\n",
        "song_2 = read_file('song2.txt')\n",
        "song_3 = read_file('song3.txt')\n",
        "\n",
        "# Применяем предобработку к текстам песен\n",
        "texts = [song_1, song_2, song_3]\n",
        "preprocessed_texts = [preprocess_text(text) for text in texts]\n",
        "\n",
        "# Инициализация TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(preprocessed_texts)\n",
        "\n",
        "# Получаем имена фич (термы)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Преобразование в DataFrame\n",
        "tfidf_matrix = pd.DataFrame(X.toarray(), columns=feature_names)\n",
        "\n",
        "# Выводим TF-IDF матрицу\n",
        "print(\"\\nTF-IDF матрица:\")\n",
        "print(tfidf_matrix.to_string(index=False))\n"
      ]
    }
  ]
}